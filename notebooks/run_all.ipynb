{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b3e48-5ac3-4886-b8f8-d3670dcb1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "RUN ALL ANALYSES: Reproducing All Tables and Figures\n",
    "This notebook executes the full pipeline of the study:\n",
    "1. Basic academic inequality (Gini, top 10%, h-index)\n",
    "2. Temporal trends (2015â€“2024)\n",
    "3. Global North vs. Global South statistical comparison\n",
    "\n",
    "All outputs are saved to:\n",
    "- Figures: ../output/figures/\n",
    "- Tables:  ../output/tables/\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 1: SETUP AND DATA LOADING (SHARED ACROSS ALL ANALYSES)\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set relative paths (relative to notebooks/)\n",
    "input_file = \"../data/processed/processed_publications_for_mertonian_analysis.csv\"\n",
    "output_figures = \"../output/figures\"\n",
    "output_tables = \"../output/tables\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(output_figures, exist_ok=True)\n",
    "os.makedirs(output_tables, exist_ok=True)\n",
    "\n",
    "# Load and inspect data\n",
    "try:\n",
    "    data = pd.read_csv(input_file)\n",
    "    print(\"âœ… Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "print(f\"ðŸ“Š Dataset: {data.shape[0]} records Ã— {data.shape[1]} variables\")\n",
    "print(\"\\nðŸ“‹ Columns:\", data.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Helper: find column case-insensitively\n",
    "def find_column(data, candidates):\n",
    "    for name in candidates:\n",
    "        if name.lower() in [col.lower() for col in data.columns]:\n",
    "            return [col for col in data.columns if col.lower() == name.lower()][0]\n",
    "    return None\n",
    "\n",
    "# Identify key columns\n",
    "author_col = find_column(data, ['Penulis_Utama', 'First_Author', 'Author', 'Authors'])\n",
    "citation_col = find_column(data, ['Jumlah_Sitasi', 'Citations', 'Cited by', 'cited_by'])\n",
    "year_col = find_column(data, ['Tahun', 'Year', 'PY'])\n",
    "region_col = find_column(data, ['Region', 'Country_Group', 'Global_North_South', 'Affiliation_Region'])\n",
    "\n",
    "# Validate essential columns\n",
    "if not author_col or not citation_col:\n",
    "    raise KeyError(\"Required columns (author, citations) not found.\")\n",
    "\n",
    "# Standardize\n",
    "data_clean = data.rename(columns={\n",
    "    author_col: 'Primary_Author',\n",
    "    citation_col: 'Citation_Count'\n",
    "})\n",
    "\n",
    "# Clean citations\n",
    "data_clean['Citation_Count'] = pd.to_numeric(data_clean['Citation_Count'], errors='coerce')\n",
    "data_clean = data_clean.dropna(subset=['Primary_Author', 'Citation_Count'])\n",
    "data_clean = data_clean[data_clean['Citation_Count'] >= 0]\n",
    "\n",
    "# Clean author names\n",
    "data_clean['Primary_Author'] = data_clean['Primary_Author'].astype(str).str.strip()\n",
    "data_clean = data_clean[data_clean['Primary_Author'] != '']\n",
    "\n",
    "print(f\"ðŸ§¹ Cleaned dataset: {len(data_clean)} publications\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 2: BASIC INEQUALITY ANALYSIS (Gini, Top 10%, h-index)\n",
    "# =============================================================================\n",
    "print(\"\\nðŸ”¬ ANALYSIS 1: BASIC ACADEMIC INEQUALITY METRICS\\n\" + \"-\"*50)\n",
    "\n",
    "def compute_gini(x):\n",
    "    x = np.array(x)\n",
    "    if len(x) == 0 or x.sum() == 0:\n",
    "        return 0.0\n",
    "    x = x[x > 0]\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (np.sum((2 * index - n - 1) * x)) / (n * np.sum(x))\n",
    "\n",
    "# Aggregate by author\n",
    "citations_per_author = data_clean.groupby('Primary_Author')['Citation_Count'].sum().sort_values(ascending=False).values\n",
    "gini_coef = compute_gini(citations_per_author)\n",
    "\n",
    "total_citations = citations_per_author.sum()\n",
    "total_authors = len(citations_per_author)\n",
    "n_top_10 = max(1, int(0.1 * total_authors))\n",
    "pct_top_10 = (citations_per_author[:n_top_10].sum() / total_citations) * 100\n",
    "h_index = np.sum(citations_per_author >= np.arange(1, len(citations_per_author) + 1))\n",
    "\n",
    "# Display and save\n",
    "basic_results = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Gini Coefficient',\n",
    "        '% Citations by Top 10%',\n",
    "        'Estimated Global h-index',\n",
    "        'Total Unique Authors',\n",
    "        'Size of Top 10% Group'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{gini_coef:.3f}\",\n",
    "        f\"{pct_top_10:.1f}%\",\n",
    "        h_index,\n",
    "        total_authors,\n",
    "        n_top_10\n",
    "    ]\n",
    "})\n",
    "print(basic_results.to_string(index=False))\n",
    "\n",
    "basic_results.to_csv(os.path.join(output_tables, \"inequality_summary.csv\"), index=False)\n",
    "\n",
    "# Plot basic visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Academic Influence Inequality (Basic Metrics)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Lorenz Curve\n",
    "cumulative_share = np.cumsum(citations_per_author) / total_citations\n",
    "pop_cum = np.arange(1, len(cumulative_share)+1) / len(cumulative_share)\n",
    "axes[0,0].plot([0,1], [0,1], '--', color='gray')\n",
    "axes[0,0].plot(pop_cum, cumulative_share, color='red')\n",
    "axes[0,0].set_title(f'Lorenz Curve (Gini = {gini_coef:.3f})')\n",
    "axes[0,0].set_xlabel('Cumulative Authors (%)')\n",
    "axes[0,0].set_ylabel('Cumulative Citations (%)')\n",
    "\n",
    "# Top 10% pie\n",
    "axes[0,1].pie([pct_top_10, 100-pct_top_10], labels=['Top 10%', 'Other 90%'], autopct='%1.1f%%', colors=['#ff9999','#66b3ff'])\n",
    "axes[0,1].set_title('% Citations by Top 10% Authors')\n",
    "\n",
    "# Top 20 authors by pubs\n",
    "pubs = data_clean['Primary_Author'].value_counts().head(20)\n",
    "pubs.plot(kind='bar', ax=axes[1,0], color='skyblue')\n",
    "axes[1,0].set_title('Publications per Author (Top 20)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Top 20 by citations\n",
    "top20_cit = data_clean.groupby('Primary_Author')['Citation_Count'].sum().sort_values(ascending=False).head(20)\n",
    "top20_cit.plot(kind='bar', ax=axes[1,1], color='salmon')\n",
    "axes[1,1].set_title('Total Citations per Author (Top 20)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_figures, \"academic_inequality_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Basic analysis outputs saved to:\\n  - {output_tables}/inequality_summary.csv\\n  - {output_figures}/academic_inequality_analysis.png\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 3: TEMPORAL TRENDS (2015â€“2024)\n",
    "# =============================================================================\n",
    "print(\"\\nðŸ”¬ ANALYSIS 2: TEMPORAL TRENDS (2015â€“2024)\\n\" + \"-\"*50)\n",
    "\n",
    "# Add year if available\n",
    "if year_col:\n",
    "    data_clean['Publication_Year'] = pd.to_numeric(data_clean[year_col], errors='coerce')\n",
    "    data_clean = data_clean.dropna(subset=['Publication_Year'])\n",
    "    data_clean = data_clean[(data_clean['Publication_Year'] >= 2015) & (data_clean['Publication_Year'] <= 2024)]\n",
    "    \n",
    "    period_1 = data_clean[(data_clean['Publication_Year'] >= 2015) & (data_clean['Publication_Year'] <= 2019)].copy()\n",
    "    period_2 = data_clean[(data_clean['Publication_Year'] >= 2020) & (data_clean['Publication_Year'] <= 2024)].copy()\n",
    "    \n",
    "    print(f\"ðŸ“… Period 1 (2015â€“2019): {len(period_1)} publications\")\n",
    "    print(f\"ðŸ“… Period 2 (2020â€“2024): {len(period_2)} publications\")\n",
    "    \n",
    "    def compute_metrics(df):\n",
    "        if len(df) == 0:\n",
    "            return None\n",
    "        cit = df.groupby('Primary_Author')['Citation_Count'].sum().sort_values(ascending=False).values\n",
    "        gini = compute_gini(cit)\n",
    "        total = cit.sum()\n",
    "        authors = len(cit)\n",
    "        n_top = max(1, int(0.1 * authors))\n",
    "        pct = (cit[:n_top].sum() / total) * 100 if total > 0 else 0\n",
    "        h_idx = np.sum(cit >= np.arange(1, len(cit)+1))\n",
    "        return {'Gini': round(gini,3), 'Top10Pct': f\"{pct:.1f}%\", 'h_index': h_idx, 'Authors': authors}\n",
    "    \n",
    "    m1 = compute_metrics(period_1)\n",
    "    m2 = compute_metrics(period_2)\n",
    "    \n",
    "    if m1 and m2:\n",
    "        temporal_table = pd.DataFrame({\n",
    "            'Metric': ['Gini Coefficient', 'Top 10% Citation Share', 'Estimated h-index', 'Total Unique Authors'],\n",
    "            '2015â€“2019': [m1['Gini'], m1['Top10Pct'], m1['h_index'], m1['Authors']],\n",
    "            '2020â€“2024': [m2['Gini'], m2['Top10Pct'], m2['h_index'], m2['Authors']]\n",
    "        })\n",
    "        print(temporal_table.to_string(index=False))\n",
    "        temporal_table.to_csv(os.path.join(output_tables, \"temporal_inequality_trends.csv\"), index=False)\n",
    "        \n",
    "        # Plot trends\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14,10))\n",
    "        fig.suptitle('Temporal Trends in Academic Inequality (2015â€“2024)', fontsize=16, fontweight='bold')\n",
    "        colors = ['#4E79A7', '#F28E2B']\n",
    "        \n",
    "        metrics = [\n",
    "            ([m1['Gini'], m2['Gini']], 'Gini Coefficient', 'Gini Value'),\n",
    "            ([float(m1['Top10Pct'].strip('%')), float(m2['Top10Pct'].strip('%'))], 'Top 10% Citation Share', 'Percentage (%)'),\n",
    "            ([m1['h_index'], m2['h_index']], 'Estimated Global h-index', 'h-index'),\n",
    "            ([m1['Authors'], m2['Authors']], 'Total Unique Authors', 'Count')\n",
    "        ]\n",
    "        \n",
    "        for i, (vals, title, ylabel) in enumerate(metrics):\n",
    "            ax = axes[i//2, i%2]\n",
    "            bars = ax.bar(['2015â€“2019', '2020â€“2024'], vals, color=colors, edgecolor='black')\n",
    "            ax.set_title(title, fontweight='bold')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            for bar, v in zip(bars, vals):\n",
    "                ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+ (0.02 if i==0 else (1 if i==1 else (2 if i==2 else 10))), \n",
    "                        f\"{v:.3f}\" if i==0 else (f\"{v:.1f}%\" if i==1 else str(int(v))), \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            ax.spines[['top','right']].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout(rect=[0,0,1,0.95])\n",
    "        plt.savefig(os.path.join(output_figures, \"academic_inequality_trends.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… Temporal analysis outputs saved to:\\n  - {output_tables}/temporal_inequality_trends.csv\\n  - {output_figures}/academic_inequality_trends.png\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Not enough data for temporal analysis.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Year column not found. Skipping temporal analysis.\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 4: GLOBAL NORTH vs. GLOBAL SOUTH COMPARISON\n",
    "# =============================================================================\n",
    "print(\"\\nðŸ”¬ ANALYSIS 3: GLOBAL NORTH vs. GLOBAL SOUTH\\n\" + \"-\"*50)\n",
    "\n",
    "if region_col:\n",
    "    data_clean['Region_Group'] = data_clean[region_col].astype(str).str.strip().str.title()\n",
    "    \n",
    "    # Standardize regions\n",
    "    north_labels = {'Global North', 'North', 'Developed', 'High Income'}\n",
    "    south_labels = {'Global South', 'South', 'Developing', 'Low Income', 'Middle Income'}\n",
    "    \n",
    "    def classify_region(label):\n",
    "        if label in north_labels:\n",
    "            return 'Global North'\n",
    "        elif label in south_labels:\n",
    "            return 'Global South'\n",
    "        else:\n",
    "            return label  # keep as-is if unknown\n",
    "    \n",
    "    data_clean['Region_Std'] = data_clean['Region_Group'].apply(classify_region)\n",
    "    \n",
    "    if 'Global North' in data_clean['Region_Std'].values and 'Global South' in data_clean['Region_Std'].values:\n",
    "        filtered = data_clean[data_clean['Region_Std'].isin(['Global North', 'Global South'])]\n",
    "        gn = filtered[filtered['Region_Std'] == 'Global North']['Citation_Count']\n",
    "        gs = filtered[filtered['Region_Std'] == 'Global South']['Citation_Count']\n",
    "        \n",
    "        print(f\"ðŸŒ Global North: {len(gn)} publications\")\n",
    "        print(f\"ðŸŒ Global South: {len(gs)} publications\")\n",
    "        \n",
    "        # Statistical test\n",
    "        u_stat, p_val = stats.mannwhitneyu(gn, gs, alternative='greater')\n",
    "        def cliffs_delta(x, y):\n",
    "            n_x, n_y = len(x), len(y)\n",
    "            delta = sum(1 if xi > yj else (-1 if xi < yj else 0) for xi in x for yj in y)\n",
    "            return delta / (n_x * n_y) if n_x * n_y > 0 else np.nan\n",
    "        cliff_d = cliffs_delta(gn.values, gs.values)\n",
    "        \n",
    "        # Interpret effect\n",
    "        d_abs = abs(cliff_d)\n",
    "        effect = \"Negligible\" if d_abs < 0.147 else \"Small\" if d_abs < 0.33 else \"Medium\" if d_abs < 0.474 else \"Large\"\n",
    "        \n",
    "        # Results table\n",
    "        stats_results = pd.DataFrame({\n",
    "            'Metric': [\n",
    "                'Mann-Whitney U',\n",
    "                'p-value',\n",
    "                \"Cliff's Delta\",\n",
    "                'Effect Size',\n",
    "                'Median Citations (GN)',\n",
    "                'Median Citations (GS)'\n",
    "            ],\n",
    "            'Value': [\n",
    "                round(u_stat, 2),\n",
    "                f\"{p_val:.2e}\" if p_val < 0.001 else f\"{p_val:.4f}\",\n",
    "                round(cliff_d, 3),\n",
    "                effect,\n",
    "                round(gn.median(), 2),\n",
    "                round(gs.median(), 2)\n",
    "            ]\n",
    "        })\n",
    "        print(stats_results.to_string(index=False))\n",
    "        stats_results.to_csv(os.path.join(output_tables, \"north_south_citation_inequality_stats.csv\"), index=False)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.boxplot(data=filtered, x='Region_Std', y='Citation_Count', order=['Global North','Global South'], \n",
    "                    palette=['#4E79A7','#F28E2B'])\n",
    "        plt.yscale('log')\n",
    "        plt.title('Citation Distribution: Global North vs. Global South', fontweight='bold')\n",
    "        plt.xlabel('Region Group')\n",
    "        plt.ylabel('Citations (log scale)')\n",
    "        for i, group in enumerate(['Global North','Global South']):\n",
    "            n = len(filtered[filtered['Region_Std'] == group])\n",
    "            plt.text(i, plt.ylim()[0]*1.2, f'n = {n}', ha='center', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_figures, \"north_south_citation_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… North-South analysis outputs saved to:\\n  - {output_tables}/north_south_citation_inequality_stats.csv\\n  - {output_figures}/north_south_citation_distribution.png\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Could not identify both 'Global North' and 'Global South' groups.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Region column not found. Skipping North-South analysis.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ ALL ANALYSES COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"ðŸ“ All outputs are saved in:\\n  - {output_figures}/\\n  - {output_tables}/\")\n",
    "print(\"ðŸ’¡ To reproduce: Run all cells in this notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
