{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc3821-8a22-45f0-9eac-fdb1d5e7665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "STATISTICAL TESTING OF CITATION INEQUALITY\n",
    "Global North vs. Global South â€” With Inferential Statistics and Effect Size\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Define relative paths (relative to notebooks/) ---\n",
    "input_file = \"../data/processed/processed_publications_for_mertonian_analysis.csv\"\n",
    "output_figures = \"../output/figures\"\n",
    "output_tables = \"../output/tables\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_figures, exist_ok=True)\n",
    "os.makedirs(output_tables, exist_ok=True)\n",
    "\n",
    "# --- Load data ---\n",
    "try:\n",
    "    data = pd.read_csv(input_file)\n",
    "    print(\"âœ… Dataset successfully loaded.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file}\")\n",
    "\n",
    "print(f\"ðŸ“Š Dataset dimensions: {data.shape[0]} observations Ã— {data.shape[1]} variables\")\n",
    "print(\"\\nðŸ“‹ Columns in dataset:\")\n",
    "print(data.columns.tolist())\n",
    "print()\n",
    "\n",
    "# --- Identify key columns dynamically ---\n",
    "def find_column(data, candidate_names):\n",
    "    for name in candidate_names:\n",
    "        if name.lower() in [col.lower() for col in data.columns]:\n",
    "            return [col for col in data.columns if col.lower() == name.lower()][0]\n",
    "    return None\n",
    "\n",
    "# Find citation and region/group columns\n",
    "citation_col = find_column(data, [\n",
    "    'Jumlah_Sitasi', 'Cited by', 'Citations', 'cited_by',\n",
    "    'Jumlah Sitasi', 'Sitasi', 'citation_count'\n",
    "])\n",
    "\n",
    "region_col = find_column(data, [\n",
    "    'Region', 'Country_Group', 'Global_North_South', 'Affiliation_Region',\n",
    "    'Region_Group', 'North_South', 'Global_South'\n",
    "])\n",
    "\n",
    "if not citation_col:\n",
    "    raise KeyError(\"Citation column not found. Please check column names.\")\n",
    "if not region_col:\n",
    "    raise KeyError(\"Region/Group column (e.g., 'Region', 'Country_Group') not found.\")\n",
    "\n",
    "print(f\"ðŸ” Citation column identified: '{citation_col}'\")\n",
    "print(f\"ðŸ” Region/Group column identified: '{region_col}'\")\n",
    "\n",
    "# Standardize column names\n",
    "data_clean = data.rename(columns={\n",
    "    citation_col: 'Citation_Count',\n",
    "    region_col: 'Region_Group'\n",
    "})\n",
    "\n",
    "# --- Data cleaning ---\n",
    "data_clean['Citation_Count'] = pd.to_numeric(data_clean['Citation_Count'], errors='coerce')\n",
    "data_clean = data_clean.dropna(subset=['Citation_Count', 'Region_Group'])\n",
    "\n",
    "# Keep only non-negative citations\n",
    "data_clean = data_clean[data_clean['Citation_Count'] >= 0]\n",
    "\n",
    "# Ensure Region_Group values are standardized (case-insensitive)\n",
    "data_clean['Region_Group'] = data_clean['Region_Group'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Identify unique groups\n",
    "unique_groups = sorted(data_clean['Region_Group'].unique())\n",
    "print(f\"ðŸŒ Unique region/group categories detected: {unique_groups}\")\n",
    "\n",
    "# --- Validate expected groups: Global North vs. Global South ---\n",
    "# We assume the data uses labels like \"Global North\", \"Global South\", or similar.\n",
    "# If your data uses different labels (e.g., \"North\", \"South\"), adjust the mapping below.\n",
    "\n",
    "# Common mappings (customize if needed)\n",
    "north_labels = {'Global North', 'North', 'Developed', 'High Income'}\n",
    "south_labels = {'Global South', 'South', 'Developing', 'Low Income', 'Middle Income'}\n",
    "\n",
    "# Map to standardized categories\n",
    "def classify_region(label):\n",
    "    if label in north_labels:\n",
    "        return 'Global North'\n",
    "    elif label in south_labels:\n",
    "        return 'Global South'\n",
    "    else:\n",
    "        # If unsure, keep original but warn\n",
    "        print(f\"âš ï¸  Unrecognized region label: '{label}'. Keeping as-is.\")\n",
    "        return label\n",
    "\n",
    "data_clean['Region_Standardized'] = data_clean['Region_Group'].apply(classify_region)\n",
    "\n",
    "# Filter to only Global North and Global South if both exist\n",
    "if 'Global North' in data_clean['Region_Standardized'].values and 'Global South' in data_clean['Region_Standardized'].values:\n",
    "    data_filtered = data_clean[data_clean['Region_Standardized'].isin(['Global North', 'Global South'])]\n",
    "    print(\"âœ… Analyzing: Global North vs. Global South\")\n",
    "else:\n",
    "    # Fallback: use original groups if only two categories\n",
    "    if len(unique_groups) == 2:\n",
    "        data_filtered = data_clean.copy()\n",
    "        data_filtered['Region_Standardized'] = data_filtered['Region_Group']\n",
    "        print(f\"âœ… Analyzing two groups: {unique_groups[0]} vs. {unique_groups[1]}\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not identify 'Global North' and 'Global South' groups. Please ensure your region column contains these labels or adjust the mapping.\")\n",
    "\n",
    "# Final dataset\n",
    "gn_data = data_filtered[data_filtered['Region_Standardized'] == 'Global North']['Citation_Count']\n",
    "gs_data = data_filtered[data_filtered['Region_Standardized'] == 'Global South']['Citation_Count']\n",
    "\n",
    "print(f\"ðŸ“Š Global North: {len(gn_data)} publications\")\n",
    "print(f\"ðŸ“Š Global South: {len(gs_data)} publications\")\n",
    "\n",
    "# --- Statistical Testing ---\n",
    "# Mann-Whitney U Test (non-parametric, for non-normal distributions)\n",
    "u_stat, p_value = stats.mannwhitneyu(gn_data, gs_data, alternative='greater')  # GN > GS?\n",
    "\n",
    "# Cliff's Delta (effect size for non-parametric test)\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"Compute Cliff's delta: probability of difference minus probability of tie.\"\"\"\n",
    "    n_x, n_y = len(x), len(y)\n",
    "    if n_x == 0 or n_y == 0:\n",
    "        return np.nan\n",
    "    delta = 0.0\n",
    "    for xi in x:\n",
    "        for yj in y:\n",
    "            if xi > yj:\n",
    "                delta += 1\n",
    "            elif xi < yj:\n",
    "                delta -= 1\n",
    "    return delta / (n_x * n_y)\n",
    "\n",
    "cliff_d = cliffs_delta(gn_data.values, gs_data.values)\n",
    "\n",
    "# Interpret effect size (Cohen-like thresholds for Cliff's delta)\n",
    "def interpret_cliffs_delta(d):\n",
    "    d = abs(d)\n",
    "    if d < 0.147:\n",
    "        return \"Negligible\"\n",
    "    elif d < 0.33:\n",
    "        return \"Small\"\n",
    "    elif d < 0.474:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\"\n",
    "\n",
    "effect_interpretation = interpret_cliffs_delta(cliff_d)\n",
    "\n",
    "# --- Results Table ---\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Mann-Whitney U Statistic',\n",
    "        'p-value',\n",
    "        \"Cliff's Delta (Effect Size)\",\n",
    "        'Effect Size Interpretation',\n",
    "        'Median Citations (Global North)',\n",
    "        'Median Citations (Global South)',\n",
    "        'Mean Citations (Global North)',\n",
    "        'Mean Citations (Global South)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        round(u_stat, 2),\n",
    "        f\"{p_value:.2e}\" if p_value < 0.001 else f\"{p_value:.4f}\",\n",
    "        round(cliff_d, 3),\n",
    "        effect_interpretation,\n",
    "        round(gn_data.median(), 2),\n",
    "        round(gs_data.median(), 2),\n",
    "        round(gn_data.mean(), 2),\n",
    "        round(gs_data.mean(), 2)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"ðŸ”¬ STATISTICAL COMPARISON: GLOBAL NORTH vs. GLOBAL SOUTH\" + \"\\n\" + \"=\"*70)\n",
    "print(f\"â€¢ Hypothesis: Global North publications receive more citations than Global South.\")\n",
    "print(f\"â€¢ Test: Mann-Whitney U (one-tailed, Î± = 0.05)\")\n",
    "print()\n",
    "display(results_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(os.path.join(output_tables, \"north_south_citation_inequality_stats.csv\"), index=False)\n",
    "print(f\"\\nðŸ’¾ Statistical results saved to: {os.path.join(output_tables, 'north_south_citation_inequality_stats.csv')}\")\n",
    "\n",
    "# --- Visualization: Citation Distribution by Region ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=data_filtered,\n",
    "    x='Region_Standardized',\n",
    "    y='Citation_Count',\n",
    "    order=['Global North', 'Global South'],\n",
    "    palette=['#4E79A7', '#F28E2B']\n",
    ")\n",
    "plt.title('Citation Distribution: Global North vs. Global South', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Region Group', fontsize=12)\n",
    "plt.ylabel('Number of Citations', fontsize=12)\n",
    "plt.yscale('log')  # Log scale for better visibility\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add sample sizes\n",
    "for i, group in enumerate(['Global North', 'Global South']):\n",
    "    n = len(data_filtered[data_filtered['Region_Standardized'] == group])\n",
    "    plt.text(i, plt.ylim()[0] * 1.2, f'n = {n}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(output_figures, \"north_south_citation_distribution.png\")\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Visualization saved to: {plot_path}\")\n",
    "\n",
    "# --- Interpretation ---\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    conclusion = \"Statistically significant evidence that Global North publications receive more citations than Global South.\"\n",
    "else:\n",
    "    conclusion = \"No statistically significant difference in citation counts between Global North and Global South.\"\n",
    "\n",
    "print(\"\\n\" + \"ðŸ“ INTERPRETATION\" + \"\\n\" + \"-\"*50)\n",
    "print(f\"â€¢ {conclusion}\")\n",
    "print(f\"â€¢ Effect size (Cliff's Delta = {cliff_d:.3f}) indicates a '{effect_interpretation}' difference.\")\n",
    "print(f\"â€¢ Median citations: GN = {gn_data.median():.1f}, GS = {gs_data.median():.1f}\")\n",
    "print(\"\\nâž¡ï¸ These results suggest structural inequalities in academic visibility and impact along Global Northâ€“South lines.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
